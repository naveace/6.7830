\section{Introduction}
Prinicipal Component Analysis is a mainstay in a wide variety of data analysis applications. It has the benefits of being simultaneously easy to understand--requiring no more than introductory linear algebra--while also being a powerful tool for dimensionality reduction, noise reduction, and data visualization. Abundant tutorials explaining the intuition behind PCA and readily available implementations in common open-source data analysis tools has furthered its popularity even among non-experts.

However Probabilistic PCA (PPCA)--a simple extension of PCA to a fully probabilistic model--has seen considerably less use in practice. Reasons for this disparity vary, however one major hurdle to using the model may be the lack of easily accessible educational content explaining how PPCA works and what its benefits can be. We aim to bridge this gap by providing an in-depth tutorial on PPCA with examples ranging from the underlying model to applications on real datasets. We hope that our tutorial enables more people to use PPCA in their own work and inspires the creation of additional educational content on the model.

\section{Background on PPCA}
PPCA is a simple and straightforward probabilistic extension of PCA. Like PCA, it models data as a linear mapping from a latent feature space to data space. The model can be succintly summarized as:
\begin{align*}
    \mathbf{z} &\sim \mathcal{N}(\mathbf{0}, \mathbf{I}_{M}) \\
    \mathbf{x} &\sim \mathcal{N}(\mathbf{Wz} + \boldsymbol{\mu}, \sigma^2\mathbf{I}_{D})
\end{align*}
where $\mathbf{W}, \boldsymbol{\mu}, $ and $\sigma^2$ are parameters of the model. It turns out that MLE solutions for $\mathbf{W}$ and $\sigma^2$ are very closely related to the solutions to PCA as they correspond to eigenvectors and eigenvalues of the sample covariance matrix. We direct the interested reader to \citet{bishop2006pattern} for a much more in-depth theoretical analysis and \citet{tipping1999probabilistic} for the original derivations. In our tutorial we instead focus on intuition, practical computation, and applications.



