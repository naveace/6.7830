% I want to say something along the lines of "there are lots of methods out there, 
% but they are all designed for some specific task and we don't know whether they are the "best" across different architectures and datasets
% Medical machine learning has seen a surge of popularity in recent years, with chest X-ray classification being one of the most prominent examples.
% While many new methods have been proposed as advancing the state of the art for chest X-ray classification,
% it is unclear whether these methods represent fundamental advancements in the field or are simply able to perform marginally better on a specific dataset.
% In this work we present a systematic and standardized study of the performance of 120 chest X-ray classification methods across several common benchmarks.
% We find that when accounting for uncertainties at both model and data levels, all methods are comparable to that of a simple baseline classifier.
% Our findings underscore the importance of controlled comparison and examining the consistency of method performance in chest X-ray classification to ensure the development of truly generalizable methods.
While recent models for chest x-ray classification have outperformed human radiologists on chest x-ray benchmarks, it is unclear what design choices have led to this performance. To better understand the effect of these choices, we conduct a comparison of design choices across a several components relevant to chest x-ray classification models. We find that the impact of common design choices on performance is minimal. Furthermore domain-specific design choices provide no significant boost over domain-independent baselines. Our findings underscore the need for further exploration of what design choices are most effective in the chest x-ray domain.
